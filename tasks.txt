- mongoi needs cleaning up:
    * function names could be clearer
    * get should not return generator, etc
- model_base functions that refer to Y can change:sparse
    * would probably also want to update the mongo objects!


* would like a way to tune - select 10,000 of the training set to work on, or an arbitary number
  and wrap some functions in there inluding history comparisons, and dev set acccuracy. there
  should be an algorithm to automatically search for good parameters, a nice way to display
  results, etc.
  ALGORITHM
    - define some default parameters
    - along the dimension of each parameter, moves either side of the default
      and assesses relevant metrics to compare the paremeters, and build diagrams
    - repeats training processes on its own to search until finished
    - prints a final report


Goals:
1. Get my hands on a well trained set of parameters to do transfer learning
    a. try the lower learning rate for Parikh model
    b. look at implementation details for errors
    c. do I want to investigate batch size?
2. Start working on encoding models
    a. keep reading papers
    b. implement promising ideas
3. Make the training process FASTER
    e. async buffer filling
4. Clean up my training process
    a. global step is not being saved properly

Training Process:
* Create separate checkpoint files based on config settings automatically
* Back up parameters in separate folders at certain times
* Add an option to look at accuracy on dev / train after each epoch and record that history
    - visualizing on TB may also be great

Models:
* Assess performance on properly clean data set:
    - no gold labels removed
    - no word vectors removed
    - prepending null token

New DataSet:
* Download the new data set, process it, get it in there, build the infrastructure to be able to use it

Parkih:
- OOV words hashed to one of 100 random vectors, then projected
- 2 layers with 200 neurons
- dropout rate 0.2
- LR = 0.05

* Global step is still not being saved properly
* It would also be nice if the number of epochs were saved on the model
* I can define the batch length and then automatically calculate the number of iterations given the collection size